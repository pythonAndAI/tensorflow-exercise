卷积神经网络--->Convolutional Neural Network，CNN

1.卷积神经网络的应用非常广泛，在自然语言处理、医药发现、灾难气候发现甚至围棋人工智能程序都有应用。

2.卷积神经网络中的著名数据集和模型。
2.1 数据集
2.1.1 MNIST数据集：是一个手写体识别数据集，图片的大小为28*28，主要分为0-9的数字，下载地址为http://yann.lecun.com/exdb/mnist/
2.1.2 CIFAR(CIFAR-10和CIFAR-100):是一个图像分类数据集，它们都是图像词典项目中800万张图片的一个子集，CIFAR数据集中的图片大小为32*32，所以放大之后图片比较模糊，CIFAR官网https://www.cs.toronto.edu/~kriz/cifar.html
提供了不同格式的CIFAR数据集下载。CIFAR-10收集了来自10个不同种类的60000张图片，图片大小都是固定的且每一张图片中仅包含一个种类的实体，和MNIST数据集最大的区别是图片由黑白变成了彩色，且分类难度也相对更高。
在CIFAR-10数据集上，人工标注的正确率大概为94%。
2.1.3 ImageNet数据集：是一个基于WordNet的大型图像数据库。在ImageNet中，将近1500万图片被关联到了WordNet的大约20000个名词同义词集上。目前每一个与ImageNet相关的WordNet同义词集都代表了现实世界中的一个实体，可以被
认为是分类问题中的一个别类。ImageNet中的图片都是从互联网上爬取下来的，并且通过亚马逊的人工标注服务将图片分类到WordNet的同义词集上。在ImageNet的图片中，一张图片中可能出现多个同义词集所代表的实体。ImageNet官网为
http://image-net.org/challenges/LSVRC/2012/。ImageNet图像分类数据集上的top-5正确率。top-N正确率指的是图像识别算法给出前N个答案中有一个是正确的概率。
2.2 模型
2.2.1 在ImageNet数据集上面模型的正确率：LeNet-v4-->ResNet-->Inception v3-->LeNet-->VGG-->ZF-->AlexNet

3.卷积神经网络简介
3.1. 在全连接神经网络中，每相邻两层之间的节点都有边相连，于是一般会将每一层全连接层中的节点组织成一列，这样方便显示连接结构。而对于卷积神经网络，相邻两层之间只有部分节点相连，为了展示每一层神经元的维度，一般会将
每一层卷积层的节点组织成一个三维矩阵。所以全连接和卷积的结构相似。
3.2 卷积神经网络的输入层就是图像的原始像素，而输出层中的每一个节点代表了不同类别的可信度。卷积神经网络和全连接神经网络的唯一区别就在于神经网络中相邻两层的连接方式。
3.3 全连接的弊端：使用全连接神经网络的最大问题在于全连接层的参数太多。对于MNIST数据，每一张图片的大小是28x28x1，其中28x28为图片的大小，x1表示图片是黑白的，只有一个色彩通道。假设第一层的隐藏层的节点数为500个，那么
一个全连接层的神经网络将有28x28x500+500=392500个参数。当图片更大时，比如在CIFAR-10数据集中，图片的大小为32x32x3，其中32x32表示图片的大小，x3表示图片是通过红绿蓝三个色彩通道表示的。这样输入层就有3072个节点，如果第一
层全连接层仍然是500个节点，那么这一层全连接神经网络将有32x32x3x500+500=150万个参数。参数增多除了导致计算速度减慢，还很容易导致过拟合问题。所以需要一个更合理的神经网络结构来有效地减少神经网络中的参数个数。
卷积神经网络就可以达到这个目的。
3.4 卷积神经网络架构图：输入层--->卷积层1--->池化层1--->卷积层2--->池化层2--->全连接层1--->全连接层2--->Softmax--->输出层。在卷积神经网络的前几层中，每一层的节点都被组织成一个三维矩阵。比如处理CIFAR-10数据集中的图片时，
可以将输入层组织成一个32x32x3的三维矩阵。并且卷积神经网络中前几层中每一个节点只和上一层中部分的节点相连。
3.5 组成。
3.5.1 输入层：输入层是整个神经网络的输入，在处理图像的卷积神经网络中，它一般代表了一张图片的像素矩阵。比如3.4的结构，最左侧的三维矩阵就可以代表一张图片。其中三维矩阵的长和宽代表了图像的大小，而三维矩阵的深度代表了
图像的色彩通道，比如黑白图片的深度为1，而在RGB色彩模式下，图像的深度为3.从输入层开始，卷积神经网络通过不同的神经网络结构将上一层的三维矩阵转化为下一层的三维矩阵，直到最后的全连接层。
3.5.2 卷积层：卷积层的每一个节点的输入只是上一层神经网络的一小块，这个小块常用的大小为3x3或者5x5。卷积层试图将神经网络中的每一小块进行更深入地分析从而得到抽象程度更高的特征。一般来说，通过卷积层处理过的节点矩阵会
变得更深，所以在3.4可以看到经过卷积层之后的节点矩阵的深度会增加。
3.5.3 池化层(Pooling)：池化层神经网路不会改变三维矩阵的深度，但是它可以缩小矩阵的大小。池化操作可以认为是将一张分辨率高较高的图片转化为分辨率较低的图片，通过池化层，可以进一步缩小最后全连接层中节点的个数，从而达到
减少整个神经网络中参数的目的。
3.5.4 全连接层：在经过多轮卷积层和池化层的处理之后，在卷积神经网络的最后一般会是由1到2个全连接层来给出最后的分类结果。经过几轮卷积层和池化层的处理之后，可以认为图像中的信息已经被抽象成了信息含量更高的特征。我们可以
将卷积层和池化层看成自动图像特征提取的过程，在特征提取完成之后，仍然需要使用全连接层来完成分类任务。
3.5.5 Softmax层：Softmax层主要用于分类问题，通过Softmax层，可以得到当前样例属于不同种类的概率分布情况。


